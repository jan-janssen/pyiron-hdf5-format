{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8c0bad64-faf8-4a5d-ae50-b9044d7ef20c","cell_type":"markdown","source":"# Functions and Imports - no pyiron dependence","metadata":{}},{"id":"28a9f0ec","cell_type":"code","source":"from h5io_browser import Pointer\nfrom h5io_browser.base import _open_hdf, _read_hdf\nimport h5py\nimport posixpath\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":1},{"id":"e6506f30-fc93-4ea4-9bf9-823ba069084c","cell_type":"code","source":"def list_groups_and_nodes(hdf, h5_path):\n    \"\"\"\n    Get the list of groups and list of nodes from an open HDF5 file\n\n    Args:\n        hdf (h5py.File): file handle of an open HDF5 file\n        h5_path (str): path inside the HDF5 file\n\n    Returns:\n        list, list: list of groups and list of nodes\n    \"\"\"\n    groups = set()\n    nodes = set()\n    try:\n        h = hdf[h5_path]\n        for k in h.keys():\n            if isinstance(h[k], h5py.Group):\n                groups.add(k)\n            else:\n                nodes.add(k)\n    except KeyError:\n        pass\n    return list(groups), list(nodes)","metadata":{"trusted":true},"outputs":[],"execution_count":2},{"id":"f34e4b06-4d5c-4593-9dd3-0b9fd51261ce","cell_type":"code","source":"def read_dict_from_hdf(\n    file_name, h5_path, recursive=False, group_paths=[], slash=\"ignore\"\n):\n    \"\"\"\n    Read data from HDF5 file into a dictionary - by default only the nodes are converted to dictionaries, additional\n    sub groups can be specified using the group_paths parameter.\n    Args:\n       file_name (str): Name of the file on disk\n       h5_path (str): Path to a group in the HDF5 file from where the data is read\n       recursive (bool): Load all subgroups recursively\n       group_paths (list): list of additional groups to be included in the dictionary, for example:\n                           [\"input\", \"output\", \"output/generic\"]\n                           These groups are defined relative to the h5_path.\n       slash (str): 'ignore' | 'replace' Whether to replace the string {FWDSLASH} with the value /. This does\n                    not apply to the top level name (title). If 'ignore', nothing will be replaced.\n    Returns:\n       dict:     The loaded data. Can be of any type supported by ``write_hdf5``.\n    \"\"\"\n\n    def get_dict_from_nodes(store, h5_path, slash=\"ignore\"):\n        \"\"\"\n        Load all nodes from an HDF5 path into a dictionary\n        Args:\n            store (str): Name of the file on disk, or file-like object.  Note: for files created with the 'core'\n                         driver, HDF5 still requires this be non-empty.:\n            h5_path (str): Path to a group in the HDF5 file from where the data is read\n            slash (str): 'ignore' | 'replace' Whether to replace the string {FWDSLASH} with the value /. This does\n                         not apply to the top level name (title). If 'ignore', nothing will be replaced.\n        Returns:\n            dict:        The loaded data. Can be of any type supported by ``write_hdf5``.\n        \"\"\"\n        return {\n            n: _read_hdf(\n                hdf_filehandle=store,\n                h5_path=get_h5_path(h5_path=h5_path, name=n),\n                slash=slash,\n            )\n            for n in list_groups_and_nodes(hdf=store, h5_path=h5_path)[1]\n        }\n\n    def resolve_nested_dict(group_path, data_dict):\n        \"\"\"\n        Turns a dict with a key containing slashes into a nested dict.  {'/a/b/c': 1} -> {'a': {'b': {'c': 1}\n        Args:\n            group_path (str): path inside the HDF5 file the data_dictionary was loaded from\n            data_dict (dict): dictionary with data loaded from the HDF5 file\n        Returns:\n            dict: hierarchical dictionary\n        \"\"\"\n        groups = group_path.split(\"/\")\n        nested_dict = data_dict\n        for g in groups[::-1]:\n            nested_dict = {g: nested_dict}\n        return nested_dict\n\n    def get_groups_hdf(hdf, h5_path):\n        \"\"\"\n        Get all sub-groups of a given HDF5 path\n        Args:\n            hdf (str): Name of the file on disk, or file-like object.  Note: for files created with the 'core'\n                       driver, HDF5 still requires this be non-empty.:\n            h5_path (str): Path to a group in the HDF5 file from where the data is read\n        Returns:\n            list: list of HDF5 groups\n        \"\"\"\n        try:\n            h = hdf[h5_path]\n            group_lst = []\n            for group in [h[k].name for k in h.keys() if isinstance(h[k], h5py.Group)]:\n                group_lst += [group] + get_groups_hdf(hdf=hdf, h5_path=group)\n            return group_lst\n        except KeyError:\n            return []\n\n    def merge_dict(main_dict, add_dict):\n        \"\"\"\n        Merge two dictionaries recursively\n\n        Args:\n            main_dict (dict): The primary dictionary, the secondary dictionary is merged into\n            add_dict (dict): The secondary dictionary which is merged in the primary dictionary\n\n        Returns:\n            dict: The merged dictionary with all keys\n        \"\"\"\n        for k, v in add_dict.items():\n            if k in main_dict.keys() and isinstance(v, dict):\n                main_dict[k] = merge_dict(main_dict=main_dict[k], add_dict=v)\n            else:\n                main_dict[k] = v\n        return main_dict\n\n    if recursive and len(group_paths) > 0:\n        raise ValueError(\n            \"Loading subgroups can either be defined by the group paths \",\n            group_paths,\n            \" or by the recursive \",\n            recursive,\n            \" parameter. Specifying both lead to this ValueError.\",\n        )\n\n    with _open_hdf(file_name, mode=\"r\") as store:\n        output_dict = get_dict_from_nodes(store=store, h5_path=h5_path, slash=slash)\n        if h5_path == \"/\" and recursive:\n            group_paths = [g[1:] for g in get_groups_hdf(hdf=store, h5_path=h5_path)]\n        elif h5_path[0] != \"/\" and recursive:\n            group_paths = [\n                g[len(\"/\" + h5_path) + 1 :]\n                for g in get_groups_hdf(hdf=store, h5_path=\"/\" + h5_path)\n            ]\n        elif recursive:\n            group_paths = [\n                g[len(h5_path) + 1 :]\n                for g in get_groups_hdf(hdf=store, h5_path=h5_path)\n            ]\n        for group_path in group_paths:\n            output_dict = merge_dict(\n                main_dict=output_dict,\n                add_dict=resolve_nested_dict(\n                    group_path=group_path,\n                    data_dict=get_dict_from_nodes(\n                        store=store,\n                        h5_path=get_h5_path(h5_path=h5_path, name=group_path),\n                        slash=slash,\n                    ),\n                ),\n            )\n    return output_dict","metadata":{"trusted":true},"outputs":[],"execution_count":3},{"id":"80fe461a-e94c-418b-b605-83a4309f7410","cell_type":"code","source":"def get_h5_path(h5_path, name):\n    \"\"\"\n    Combine the current h5_path with the relative path\n\n    Args:\n        h5_path (str): absolute path of the node in the hdf5 file\n        name (str): relative path to be added to the absolute path\n\n    Returns:\n        str: combined path\n    \"\"\"\n    return posixpath.join(h5_path, name)","metadata":{"trusted":true},"outputs":[],"execution_count":4},{"id":"c14198a4-2324-4bb6-bff8-fcc5818dcdfc","cell_type":"markdown","source":"# Create LAMMPS job","metadata":{}},{"id":"ffd464bb","cell_type":"code","source":"from pyiron_atomistics import Project","metadata":{"trusted":true},"outputs":[],"execution_count":5},{"id":"0d95fc61","cell_type":"code","source":"pr = Project(\"test\")","metadata":{"trusted":true},"outputs":[],"execution_count":6},{"id":"64427095","cell_type":"code","source":"pr.remove_jobs(recursive=True, silently=True)","metadata":{"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9543489fff54fb5a51f7899cb028455"}},"metadata":{}}],"execution_count":7},{"id":"09b53d07","cell_type":"code","source":"structure = pr.create.structure.ase.bulk(\"Al\", cubic=True)","metadata":{"trusted":true},"outputs":[],"execution_count":8},{"id":"264e6228","cell_type":"code","source":"structure.set_repeat([9,9,9])","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_2835/461746984.py:1: DeprecationWarning: pyiron_atomistics.atomistics.structure.atoms.set_repeat is deprecated: Use Atoms.repeat.\n  structure.set_repeat([9,9,9])\n","output_type":"stream"}],"execution_count":9},{"id":"c2be1def","cell_type":"code","source":"len(structure)","metadata":{"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2916"},"metadata":{}}],"execution_count":10},{"id":"e26dd327","cell_type":"code","source":"job = pr.create.job.Lammps(\"lmp\")","metadata":{"trusted":true},"outputs":[],"execution_count":11},{"id":"f29a4da4","cell_type":"code","source":"job.structure =structure","metadata":{"trusted":true},"outputs":[],"execution_count":12},{"id":"b5e9c630","cell_type":"code","source":"job.potential = '2002--Mishin-Y--Ni-Al--LAMMPS--ipr1'","metadata":{"trusted":true},"outputs":[],"execution_count":13},{"id":"d3dad632","cell_type":"code","source":"job.calc_md(n_ionic_steps=1000, n_print=10, temperature=500.0)","metadata":{"trusted":true},"outputs":[],"execution_count":14},{"id":"97a17236","cell_type":"code","source":"job.run()","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"The job lmp was saved and received the ID: 1\n","output_type":"stream"}],"execution_count":15},{"id":"f2ee05b2-b077-4d3a-a90c-84c82b1f33ff","cell_type":"markdown","source":"# Read job dictionary","metadata":{}},{"id":"ffe89737-3017-4d1f-918f-536b0af5c9f6","cell_type":"code","source":"job_dict = read_dict_from_hdf(\n    file_name=job.project_hdf5.file_name,\n    h5_path=\"/\",\n    recursive=True,\n    group_paths=[],\n    slash='ignore',\n)","metadata":{"trusted":true},"outputs":[],"execution_count":16},{"id":"833b5bf1-7082-4eea-be5f-c7c29a5a8ae2","cell_type":"markdown","source":"# Get LAMMPS schema","metadata":{}},{"id":"59dacba5","cell_type":"code","source":"file_name = job.project_hdf5.file_name\nfile_name","metadata":{"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'/home/jovyan/test/lmp.h5'"},"metadata":{}}],"execution_count":17},{"id":"d47a3751-36e4-4e3b-ae2c-2acf311ac81d","cell_type":"code","source":"key_lst = []\ndef collect_attrs(name, obj):\n    key_lst.append(name)\n    \nwith h5py.File(file_name, 'r') as f:\n    f.visititems(collect_attrs)","metadata":{"trusted":true},"outputs":[],"execution_count":18},{"id":"fe15d593-fdd4-4b22-8714-d92abf30bba2","cell_type":"code","source":"node_lst = [g for i, g in enumerate(key_lst) if len([k for k in key_lst[i:] if g in k]) == 1]\nnode_lst","metadata":{"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['lmp/DICT_VERSION',\n 'lmp/HDF_VERSION',\n 'lmp/NAME',\n 'lmp/OBJECT',\n 'lmp/TYPE',\n 'lmp/VERSION',\n 'lmp/executable',\n 'lmp/input/control_inp/DICT_VERSION',\n 'lmp/input/control_inp/NAME',\n 'lmp/input/control_inp/OBJECT',\n 'lmp/input/control_inp/TYPE',\n 'lmp/input/control_inp/VERSION',\n 'lmp/input/control_inp/data_dict',\n 'lmp/input/generic/DICT_VERSION',\n 'lmp/input/generic/NAME',\n 'lmp/input/generic/OBJECT',\n 'lmp/input/generic/TYPE',\n 'lmp/input/generic/VERSION',\n 'lmp/input/generic/data_dict',\n 'lmp/input/generic_dict',\n 'lmp/input/interactive',\n 'lmp/input/potential_inp/DICT_VERSION',\n 'lmp/input/potential_inp/NAME',\n 'lmp/input/potential_inp/OBJECT',\n 'lmp/input/potential_inp/TYPE',\n 'lmp/input/potential_inp/VERSION',\n 'lmp/input/potential_inp/data_dict',\n 'lmp/input/potential_inp/potential/Citations',\n 'lmp/input/potential_inp/potential/Config',\n 'lmp/input/potential_inp/potential/Filename',\n 'lmp/input/potential_inp/potential/Model',\n 'lmp/input/potential_inp/potential/Name',\n 'lmp/input/potential_inp/potential/Species',\n 'lmp/input/structure/TYPE',\n 'lmp/input/structure/cell/cell',\n 'lmp/input/structure/cell/pbc',\n 'lmp/input/structure/dimension',\n 'lmp/input/structure/indices',\n 'lmp/input/structure/info',\n 'lmp/input/structure/positions',\n 'lmp/input/structure/species',\n 'lmp/input/structure/units',\n 'lmp/job_id',\n 'lmp/output/generic/cells',\n 'lmp/output/generic/energy_pot',\n 'lmp/output/generic/energy_tot',\n 'lmp/output/generic/forces',\n 'lmp/output/generic/indices',\n 'lmp/output/generic/natoms',\n 'lmp/output/generic/positions',\n 'lmp/output/generic/pressures',\n 'lmp/output/generic/steps',\n 'lmp/output/generic/temperature',\n 'lmp/output/generic/unwrapped_positions',\n 'lmp/output/generic/velocities',\n 'lmp/output/generic/volume',\n 'lmp/output/structure/TYPE',\n 'lmp/output/structure/cell/cell',\n 'lmp/output/structure/cell/pbc',\n 'lmp/output/structure/dimension',\n 'lmp/output/structure/indices',\n 'lmp/output/structure/info',\n 'lmp/output/structure/positions',\n 'lmp/output/structure/species',\n 'lmp/output/structure/units',\n 'lmp/server',\n 'lmp/status']"},"metadata":{}}],"execution_count":19},{"id":"665bf1f4-f4b1-4e7f-a2bf-a1c4216ad5f3","cell_type":"markdown","source":"# Write LAMMPS job","metadata":{}},{"id":"a85b3af6-3ae9-49f0-9d01-f5622380933e","cell_type":"code","source":"def get_node_from_job_dict(job_dict, node):\n    node_name_lst = node.split(\"/\")\n    tmp_dict = job_dict\n    for group in node_name_lst:\n        tmp_dict = tmp_dict[group]\n    return tmp_dict","metadata":{"trusted":true},"outputs":[],"execution_count":20},{"id":"c338fd0c-ff15-45d7-8227-bbe82117ca15","cell_type":"code","source":"node_dict = {node: get_node_from_job_dict(job_dict=job_dict, node=node) for node in node_lst}","metadata":{"trusted":true},"outputs":[],"execution_count":21},{"id":"12320454-cbbc-4fbe-936b-a15e8c2dd744","cell_type":"code","source":"os.remove(file_name)","metadata":{"trusted":true},"outputs":[],"execution_count":22},{"id":"989f77eb","cell_type":"code","source":"with Pointer(file_name=file_name) as hdf_file:\n    hdf_file.write_dict(node_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":23},{"id":"dbb0c2c1-1873-4a6a-8419-119bd51a4684","cell_type":"markdown","source":"# Reload job","metadata":{}},{"id":"cb00164e-25a4-4d0d-87bc-7ee9d14422f6","cell_type":"code","source":"job = pr.load(job.job_name)","metadata":{"trusted":true},"outputs":[],"execution_count":24},{"id":"8497be06-dd2c-446e-9f3f-7ea89e0aed4d","cell_type":"code","source":"job.input.control","metadata":{"trusted":true},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                Parameter  \\\n0                   units   \n1               dimension   \n2                boundary   \n3              atom_style   \n4               read_data   \n5                 include   \n6          fix___ensemble   \n7     variable___dumptime   \n8   variable___thermotime   \n9                timestep   \n10               velocity   \n11               dump___1   \n12        dump_modify___1   \n13           thermo_style   \n14          thermo_modify   \n15                 thermo   \n16                    run   \n\n                                                                                                  Value  \\\n0                                                                                                 metal   \n1                                                                                                     3   \n2                                                                                                 p p p   \n3                                                                                                atomic   \n4                                                                                         structure.inp   \n5                                                                                         potential.inp   \n6                                                                          all nvt temp 500.0 500.0 0.1   \n7                                                                                             equal 10    \n8                                                                                             equal 10    \n9                                                                                                 0.001   \n10                                                                all create 1000.0 61040 dist gaussian   \n11                                all custom ${dumptime} dump.out id type xsu ysu zsu fx fy fz vx vy vz   \n12  sort id format line \"%d %d %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g\"   \n13                                               custom step temp pe etotal pxx pxy pxz pyy pyz pzz vol   \n14                                                                                 format float %20.15g   \n15                                                                                        ${thermotime}   \n16                                                                                                 1000   \n\n   Comment  \n0           \n1           \n2           \n3           \n4           \n5           \n6           \n7           \n8           \n9           \n10          \n11          \n12          \n13          \n14          \n15          \n16          ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter</th>\n      <th>Value</th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>units</td>\n      <td>metal</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dimension</td>\n      <td>3</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>boundary</td>\n      <td>p p p</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>atom_style</td>\n      <td>atomic</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>read_data</td>\n      <td>structure.inp</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>include</td>\n      <td>potential.inp</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>fix___ensemble</td>\n      <td>all nvt temp 500.0 500.0 0.1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>variable___dumptime</td>\n      <td>equal 10</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>variable___thermotime</td>\n      <td>equal 10</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>timestep</td>\n      <td>0.001</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>velocity</td>\n      <td>all create 1000.0 61040 dist gaussian</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>dump___1</td>\n      <td>all custom ${dumptime} dump.out id type xsu ysu zsu fx fy fz vx vy vz</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>dump_modify___1</td>\n      <td>sort id format line \"%d %d %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g %20.15g\"</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>thermo_style</td>\n      <td>custom step temp pe etotal pxx pxy pxz pyy pyz pzz vol</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>thermo_modify</td>\n      <td>format float %20.15g</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>thermo</td>\n      <td>${thermotime}</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>run</td>\n      <td>1000</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"id":"b0eb0a68-29c5-4eea-bfaf-ff59a9ee505d","cell_type":"code","source":"job.input.potential","metadata":{"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"    Parameter                       Value Comment\n0  pair_style                   eam/alloy        \n1  pair_coeff  * * NiAl02.eam.alloy Ni Al        ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter</th>\n      <th>Value</th>\n      <th>Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pair_style</td>\n      <td>eam/alloy</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pair_coeff</td>\n      <td>* * NiAl02.eam.alloy Ni Al</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"id":"dccb5f83-7df1-4496-a8ce-a931738b1a7a","cell_type":"code","source":"job.output.energy_tot","metadata":{"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"array([-9427.29630088, -9430.14696684, -9432.82349157, -9433.14423094,\n       -9432.46197988, -9431.11779442, -9429.84887403, -9428.59786876,\n       -9427.38813359, -9426.70956719, -9426.59728248, -9426.49789307,\n       -9426.12272411, -9425.59921798, -9425.20912449, -9424.90209584,\n       -9424.49520497, -9423.99938741, -9423.57006459, -9423.24848256,\n       -9422.96494608, -9422.73886581, -9422.67498343, -9422.7595396 ,\n       -9422.83422591, -9422.80728218, -9422.74305075, -9422.77967415,\n       -9422.94528544, -9423.13258663, -9423.2946694 , -9423.5107131 ,\n       -9423.84002756, -9424.21163482, -9424.54837222, -9424.86419284,\n       -9425.20921977, -9425.60463137, -9426.04263383, -9426.51076414,\n       -9427.00943396, -9427.53249825, -9428.0367887 , -9428.46758844,\n       -9428.83561118, -9429.21325813, -9429.67512814, -9430.21492958,\n       -9430.73337493, -9431.12233644, -9431.37229576, -9431.54923363,\n       -9431.70507951, -9431.83867285, -9431.96559155, -9432.12935211,\n       -9432.32782949, -9432.50022218, -9432.56929247, -9432.46965105,\n       -9432.17453759, -9431.73757478, -9431.29589688, -9430.96775402,\n       -9430.73411841, -9430.48549004, -9430.13305421, -9429.65825193,\n       -9429.08087121, -9428.4381376 , -9427.78194397, -9427.19231664,\n       -9426.7309528 , -9426.36283953, -9425.98788448, -9425.55230078,\n       -9425.08847262, -9424.65426088, -9424.25553538, -9423.86590764,\n       -9423.51500222, -9423.27611974, -9423.17160248, -9423.15605392,\n       -9423.21983895, -9423.38146456, -9423.599644  , -9423.80261812,\n       -9423.984236  , -9424.18422617, -9424.4165587 , -9424.65943597,\n       -9424.9117689 , -9425.19679182, -9425.51472865, -9425.83051291,\n       -9426.15521196, -9426.56256895, -9427.10480065, -9427.7480472 ,\n       -9428.45286562])"},"metadata":{}}],"execution_count":27},{"id":"7011db5d-c324-4126-b956-5fbad85294a0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}